{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28eaf89",
   "metadata": {},
   "source": [
    "# Entrenamiento de un Modelo de Deep Learning de Inicio a Fin\n",
    "\n",
    "Este notebook cubre el proceso completo de entrenamiento de un modelo de deep learning, incluyendo:\n",
    "- Carga y visualización del dataset\n",
    "- Preparación de dataloaders\n",
    "- Definición del modelo\n",
    "- Entrenamiento\n",
    "- Validación y evaluación\n",
    "- Fine-tuning\n",
    "- Guardado y reutilización del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6460fa65",
   "metadata": {},
   "source": [
    "## Instalación de las librerías necesarias\n",
    "\n",
    "Ejecuta esta celda si estás en Google Colab o necesitas instalar las dependencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a0b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch torchvision numpy matplotlib scikit-learn seaborn pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b266c3",
   "metadata": {},
   "source": [
    "## 1. Cargar y visualizar el dataset\n",
    "\n",
    "Utilizaremos el dataset MNIST para este taller, que contiene imágenes de dígitos escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54f84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Verificar si GPU está disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8493ef8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir transformaciones para normalizar los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Cargar datos de entrenamiento y prueba\n",
    "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
    "\n",
    "print(\"Tamaño del set de entrenamiento:\", len(train_data))\n",
    "print(\"Tamaño del set de prueba:\", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530babb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar algunos ejemplos\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    image, label = train_data[i]\n",
    "    plt.imshow(image.squeeze(), cmap='gray')\n",
    "    plt.title(f\"Etiqueta: {label}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/ejemplos_mnist.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ea335c",
   "metadata": {},
   "source": [
    "## 2. Preparar los dataloaders\n",
    "\n",
    "Dividimos los datos de entrenamiento en conjuntos de entrenamiento y validación. Luego creamos los dataloaders para cada conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc13604",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación (80% - 20%)\n",
    "train_size = int(0.8 * len(train_data))\n",
    "val_size = len(train_data) - train_size\n",
    "train_subset, val_subset = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "# Definir el tamaño del batch\n",
    "batch_size = 64\n",
    "\n",
    "# Crear los dataloaders\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {train_size} muestras\")\n",
    "print(f\"Tamaño del conjunto de validación: {val_size} muestras\")\n",
    "print(f\"Tamaño del conjunto de prueba: {len(test_data)} muestras\")\n",
    "print(f\"Número de batches de entrenamiento: {len(train_loader)}\")\n",
    "print(f\"Número de batches de validación: {len(val_loader)}\")\n",
    "print(f\"Número de batches de prueba: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b31402",
   "metadata": {},
   "source": [
    "## 3. Definir el modelo\n",
    "\n",
    "Creamos una red neuronal simple para la clasificación de dígitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Definir el modelo\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Crear una instancia del modelo\n",
    "model = SimpleNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4491a08",
   "metadata": {},
   "source": [
    "## 4. Configurar función de pérdida y optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e772db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Definir la función de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ff7de",
   "metadata": {},
   "source": [
    "## 5. Entrenar el modelo\n",
    "\n",
    "Implementamos el bucle de entrenamiento y validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f4749f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para entrenar el modelo\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs, device):\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Fase de entrenamiento\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Barra de progreso para el entrenamiento\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} [Train]')\n",
    "        \n",
    "        for images, labels in train_pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Poner a cero los gradientes\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass y optimización\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calcular estadísticas\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Actualizar la barra de progreso\n",
    "            train_pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "        \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100 * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        \n",
    "        # Fase de validación\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # No calcular gradientes en la validación\n",
    "        with torch.no_grad():\n",
    "            # Barra de progreso para la validación\n",
    "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{epochs} [Val]')\n",
    "            \n",
    "            for images, labels in val_pbar:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                # Calcular estadísticas\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "                \n",
    "                # Actualizar la barra de progreso\n",
    "                val_pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    \n",
    "    return train_losses, val_losses, train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8854ad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "epochs = 10\n",
    "train_losses, val_losses, train_accs, val_accs = train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, epochs, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36755a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar las curvas de pérdida y precisión\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfica de pérdida\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Entrenamiento')\n",
    "plt.plot(range(1, epochs+1), val_losses, label='Validación')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.title('Curva de Pérdida')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Gráfica de precisión\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_accs, label='Entrenamiento')\n",
    "plt.plot(range(1, epochs+1), val_accs, label='Validación')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precisión (%)')\n",
    "plt.title('Curva de Precisión')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/curva_loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7be7e4a",
   "metadata": {},
   "source": [
    "## 6. Validación y evaluación del modelo\n",
    "\n",
    "### 6.1 Evaluación en el conjunto de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eabdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Evaluando'):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Calcular el informe de clasificación\n",
    "    report = classification_report(all_labels, all_preds, digits=4)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    return report, cm, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6482fe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "report, cm, test_preds, test_labels = evaluate_model(model, test_loader, device)\n",
    "print(\"Informe de clasificación:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la matriz de confusión\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=range(10), yticklabels=range(10))\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/confusion_matrix.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e52f0",
   "metadata": {},
   "source": [
    "### 6.2 K-Fold Cross Validation\n",
    "\n",
    "Implementaremos una validación cruzada de 5 pliegues (5-fold) para evaluar la robustez del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4f2322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def kfold_cross_validation(dataset, k=5, batch_size=64, epochs=3, device='cpu'):\n",
    "    # Preparar los datos para k-fold\n",
    "    X = torch.stack([dataset[i][0] for i in range(len(dataset))])\n",
    "    y = torch.tensor([dataset[i][1] for i in range(len(dataset))])\n",
    "    \n",
    "    # Inicializar K-Fold\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Almacenar los resultados de cada fold\n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "        print(f\"\\nFold {fold+1}/{k}\")\n",
    "        \n",
    "        # Crear subconjuntos de datos para este fold\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Crear DataLoaders\n",
    "        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "        val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "        \n",
    "        # Crear un nuevo modelo para este fold\n",
    "        fold_model = SimpleNN().to(device)\n",
    "        fold_optimizer = optim.Adam(fold_model.parameters(), lr=0.001)\n",
    "        fold_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Entrenar el modelo para este fold\n",
    "        _, _, _, _ = train_model(\n",
    "            fold_model, train_loader, val_loader, fold_criterion, fold_optimizer, epochs, device\n",
    "        )\n",
    "        \n",
    "        # Evaluar el modelo en el conjunto de validación\n",
    "        fold_model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = fold_model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Fold {fold+1} Accuracy: {accuracy:.2f}%\")\n",
    "        fold_results.append(accuracy)\n",
    "    \n",
    "    # Calcular estadísticas generales\n",
    "    mean_accuracy = sum(fold_results) / len(fold_results)\n",
    "    std_accuracy = np.std(fold_results)\n",
    "    \n",
    "    print(f\"\\nK-Fold Cross Validation Results:\")\n",
    "    print(f\"Mean Accuracy: {mean_accuracy:.2f}%\")\n",
    "    print(f\"Standard Deviation: {std_accuracy:.2f}%\")\n",
    "    \n",
    "    return fold_results, mean_accuracy, std_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40336e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar K-Fold Cross Validation (con menos epochs para reducir tiempo)\n",
    "fold_results, mean_accuracy, std_accuracy = kfold_cross_validation(\n",
    "    train_data, k=5, batch_size=64, epochs=3, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3105f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los resultados de la validación cruzada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, 6), fold_results, color='skyblue')\n",
    "plt.axhline(mean_accuracy, color='red', linestyle='--', label=f'Media: {mean_accuracy:.2f}%')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Precisión (%)')\n",
    "plt.title('Resultados de la Validación Cruzada K-Fold')\n",
    "plt.xticks(range(1, 6))\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../resultados/kfold_results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce3fc4",
   "metadata": {},
   "source": [
    "## 7. Fine-Tuning con modelo preentrenado\n",
    "\n",
    "Utilizaremos ResNet18 preentrenado y lo adaptaremos para nuestro problema de clasificación de MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f77b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "# Cargar modelo preentrenado\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "\n",
    "# Congelar todas las capas\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Modificar la primera capa para aceptar imágenes en escala de grises (1 canal)\n",
    "model_ft.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Reemplazar la capa final para tener 10 clases de salida (dígitos 0-9)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 10)\n",
    "\n",
    "# Mover el modelo a GPU si está disponible\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a7bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar solo la capa final (feature extraction)\n",
    "optimizer_ft = optim.Adam(model_ft.fc.parameters(), lr=1e-4)\n",
    "criterion_ft = nn.CrossEntropyLoss()\n",
    "\n",
    "# Entrenar con feature extraction\n",
    "epochs_ft = 5\n",
    "train_losses_ft, val_losses_ft, train_accs_ft, val_accs_ft = train_model(\n",
    "    model_ft, train_loader, val_loader, criterion_ft, optimizer_ft, epochs_ft, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo feature extraction en el conjunto de prueba\n",
    "report_ft, cm_ft, test_preds_ft, test_labels_ft = evaluate_model(model_ft, test_loader, device)\n",
    "print(\"Informe de clasificación (Feature Extraction):\\n\", report_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cb7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, descongelar todas las capas para hacer fine-tuning completo\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Usar una tasa de aprendizaje más pequeña para el fine-tuning\n",
    "optimizer_full_ft = optim.Adam(model_ft.parameters(), lr=1e-5)\n",
    "\n",
    "# Entrenar con fine-tuning completo\n",
    "epochs_full_ft = 5\n",
    "train_losses_full_ft, val_losses_full_ft, train_accs_full_ft, val_accs_full_ft = train_model(\n",
    "    model_ft, train_loader, val_loader, criterion_ft, optimizer_full_ft, epochs_full_ft, device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d1c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo con fine-tuning completo en el conjunto de prueba\n",
    "report_full_ft, cm_full_ft, test_preds_full_ft, test_labels_full_ft = evaluate_model(model_ft, test_loader, device)\n",
    "print(\"Informe de clasificación (Fine-Tuning Completo):\\n\", report_full_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c1415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar los resultados: modelo simple vs. feature extraction vs. fine-tuning completo\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Gráfica de precisión de entrenamiento\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_accs, label='Modelo Simple')\n",
    "plt.plot(range(1, epochs_ft+1), train_accs_ft, label='Feature Extraction')\n",
    "plt.plot(range(1, epochs_full_ft+1), train_accs_full_ft, label='Fine-Tuning Completo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precisión de Entrenamiento (%)')\n",
    "plt.title('Comparación de Precisión de Entrenamiento')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Gráfica de precisión de validación\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), val_accs, label='Modelo Simple')\n",
    "plt.plot(range(1, epochs_ft+1), val_accs_ft, label='Feature Extraction')\n",
    "plt.plot(range(1, epochs_full_ft+1), val_accs_full_ft, label='Fine-Tuning Completo')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Precisión de Validación (%)')\n",
    "plt.title('Comparación de Precisión de Validación')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../resultados/comparacion_precisiones.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un DataFrame con las métricas para cada modelo\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Calcular métricas para cada modelo\n",
    "metrics_simple = calculate_metrics(test_labels, test_preds)\n",
    "metrics_ft = calculate_metrics(test_labels_ft, test_preds_ft)\n",
    "metrics_full_ft = calculate_metrics(test_labels_full_ft, test_preds_full_ft)\n",
    "\n",
    "# Crear DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Modelo': ['Simple', 'Feature Extraction', 'Fine-Tuning Completo'],\n",
    "    'Exactitud': [metrics_simple[0], metrics_ft[0], metrics_full_ft[0]],\n",
    "    'Precisión': [metrics_simple[1], metrics_ft[1], metrics_full_ft[1]],\n",
    "    'Recall': [metrics_simple[2], metrics_ft[2], metrics_full_ft[2]],\n",
    "    'F1-Score': [metrics_simple[3], metrics_ft[3], metrics_full_ft[3]]\n",
    "})\n",
    "\n",
    "# Mostrar y guardar métricas\n",
    "print(metrics_df)\n",
    "metrics_df.to_csv('../resultados/comparacion_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53154bf",
   "metadata": {},
   "source": [
    "## 8. Guardar y reutilizar el modelo\n",
    "\n",
    "Guardamos los modelos entrenados para su uso futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a61c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo simple\n",
    "torch.save(model.state_dict(), '../modelos/modelo_simple.pth')\n",
    "\n",
    "# Guardar el modelo con fine-tuning completo\n",
    "torch.save(model_ft.state_dict(), '../modelos/modelo_fine_tuned.pth')\n",
    "\n",
    "print(\"Modelos guardados con éxito en la carpeta 'modelos/'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9183391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de cómo cargar el modelo guardado\n",
    "modelo_cargado = SimpleNN()\n",
    "modelo_cargado.load_state_dict(torch.load('../modelos/modelo_simple.pth'))\n",
    "modelo_cargado.to(device)\n",
    "modelo_cargado.eval()\n",
    "\n",
    "# Verificamos que funciona correctamente\n",
    "test_image, test_label = test_data[0]\n",
    "test_image = test_image.unsqueeze(0).to(device)  # Añadir dimensión del batch\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = modelo_cargado(test_image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "\n",
    "print(f\"Etiqueta real: {test_label}\")\n",
    "print(f\"Predicción: {predicted.item()}\")\n",
    "\n",
    "# Visualizar la imagen\n",
    "plt.imshow(test_image.squeeze().cpu(), cmap='gray')\n",
    "plt.title(f\"Etiqueta: {test_label}, Predicción: {predicted.item()}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c83a662",
   "metadata": {},
   "source": [
    "## 9. Conclusiones\n",
    "\n",
    "En este taller hemos completado un ciclo completo de entrenamiento de un modelo de Deep Learning:\n",
    "\n",
    "1. **Carga y visualización de datos**: Utilizamos el dataset MNIST, visualizamos ejemplos para entender los datos.\n",
    "2. **Preparación de dataloaders**: Dividimos los datos en conjuntos de entrenamiento, validación y prueba.\n",
    "3. **Definición del modelo**: Creamos una red neuronal simple para clasificación.\n",
    "4. **Entrenamiento**: Implementamos un bucle de entrenamiento completo con monitoreo de métricas.\n",
    "5. **Validación y evaluación**: Evaluamos el modelo con validación estándar y k-fold cross validation.\n",
    "6. **Fine-tuning**: Utilizamos un modelo preentrenado (ResNet18) y lo adaptamos a nuestro problema.\n",
    "7. **Guardado del modelo**: Guardamos los modelos entrenados para uso futuro.\n",
    "\n",
    "Los modelos basados en arquitecturas preentrenadas (feature extraction y fine-tuning) tienden a superar al modelo simple en términos de precisión y velocidad de convergencia, lo que demuestra el valor de la transferencia de aprendizaje incluso en tareas relativamente simples como la clasificación de MNIST."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
