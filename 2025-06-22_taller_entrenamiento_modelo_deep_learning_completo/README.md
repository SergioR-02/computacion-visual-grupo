# ğŸ¯ Taller de Entrenamiento de un Modelo de Deep Learning de Inicio a Fin

ğŸ“… **Fecha:** 2025-06-22 â€“ Fecha de realizaciÃ³n

ğŸ¯ **Objetivo del Taller:**
Guiar paso a paso el entrenamiento completo de un modelo de Deep Learning, desde la preparaciÃ³n de datos hasta la evaluaciÃ³n, validaciÃ³n cruzada, fine-tuning y exportaciÃ³n. El objetivo es que el estudiante comprenda el flujo completo y pueda aplicar estos principios a sus propios proyectos.

## ğŸ§  Conceptos Aprendidos

Lista de conceptos clave aplicados en el taller:

* **PreparaciÃ³n de datos**: Carga y visualizaciÃ³n del dataset MNIST.
* **Entrenamiento de modelos**: ImplementaciÃ³n de una red neuronal simple.
* **ValidaciÃ³n cruzada**: Uso de K-Fold Cross Validation para evaluar robustez.
* **Fine-Tuning**: AdaptaciÃ³n de un modelo preentrenado (ResNet18).
* **ExportaciÃ³n de modelos**: Guardado y reutilizaciÃ³n de modelos entrenados.

## ğŸ”§ Herramientas y Entornos

* Python + PyTorch
* NumPy
* Matplotlib
* Seaborn
* Scikit-learn
* tqdm

## ğŸ“ Estructura del Proyecto

```
2025-06-22_taller_entrenamiento_modelo_deep_learning_completo/
â”œâ”€â”€ python/
â”‚   â””â”€â”€ entrenamiento_modelo.ipynb
â”œâ”€â”€ modelos/
â”‚   â””â”€â”€ modelo_simple.pth
â”‚   â””â”€â”€ modelo_fine_tuned.pth
â”œâ”€â”€ resultados/
â”‚   â”œâ”€â”€ curva_loss.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ comparacion_precisiones.png
â”‚   â”œâ”€â”€ kfold_results.png
â”‚   â””â”€â”€ comparacion_metrics.csv
â”œâ”€â”€ README.md
```

## ğŸ§ª ImplementaciÃ³n

La implementaciÃ³n de este taller se centra en el entrenamiento de un modelo de Deep Learning utilizando el dataset MNIST. Se desarrollaron scripts en Python que permiten realizar las siguientes tareas:

- **Carga y visualizaciÃ³n de datos**: Descarga y preprocesamiento del dataset MNIST.
- **Entrenamiento de modelos**: ImplementaciÃ³n de una red neuronal simple.
- **ValidaciÃ³n cruzada**: EvaluaciÃ³n del modelo con K-Fold Cross Validation.
- **Fine-Tuning**: Uso de ResNet18 preentrenado para mejorar el rendimiento.
- **ExportaciÃ³n de modelos**: Guardado de modelos entrenados para uso futuro.

### ğŸ”¹ Etapas realizadas

1. **Carga y visualizaciÃ³n de datos**: Descarga del dataset MNIST y visualizaciÃ³n de ejemplos.
2. **PreparaciÃ³n de dataloaders**: DivisiÃ³n de datos en conjuntos de entrenamiento, validaciÃ³n y prueba.
3. **Entrenamiento de modelos**: ImplementaciÃ³n de una red neuronal simple.
4. **ValidaciÃ³n cruzada**: EvaluaciÃ³n del modelo con K-Fold Cross Validation.
5. **Fine-Tuning**: AdaptaciÃ³n de ResNet18 preentrenado.
6. **ExportaciÃ³n de modelos**: Guardado de modelos entrenados.

### ğŸ”¹ CÃ³digo relevante

ğŸ“Œ **1. Entrenamiento de modelos**

```python
train_losses, val_losses, train_accs, val_accs = train_model(
    model, train_loader, val_loader, criterion, optimizer, epochs, device
)
```

ğŸ“Œ **2. ValidaciÃ³n cruzada**

```python
fold_results, mean_accuracy, std_accuracy = kfold_cross_validation(
    train_data, k=5, batch_size=64, epochs=3, device=device
)
```

ğŸ“Œ **3. Fine-Tuning**

```python
model_ft = models.resnet18(pretrained=True)
model_ft.fc = nn.Linear(num_ftrs, 10)
train_losses_ft, val_losses_ft, train_accs_ft, val_accs_ft = train_model(
    model_ft, train_loader, val_loader, criterion_ft, optimizer_ft, epochs_ft, device
)
```

## ğŸ“Š Resultados y AnÃ¡lisis

### ğŸ“Œ Curvas de Entrenamiento y ValidaciÃ³n

![Curva de PÃ©rdida y PrecisiÃ³n](resultados/CruvaPerdida.png)


![Curva de PÃ©rdida y PrecisiÃ³n](resultados/curvaPrecision.png)

### ğŸ“Œ Matriz de ConfusiÃ³n
![Matriz de ConfusiÃ³n](resultados/matriz.png)

### ğŸ“Œ ComparaciÃ³n de Modelos
![ComparaciÃ³n de Precisiones](resultados/compracionModelos.png)

### ğŸ“Œ Resultados de K-Fold Cross Validation
![Resultados K-Fold](resultados/K-Fold.png)

### ğŸ“Œ ComparaciÃ³n de MÃ©tricas

Los resultados comparativos entre los diferentes enfoques estÃ¡n disponibles en el archivo `resultados/comparacion_metrics.csv`.

## ğŸ’¬ ReflexiÃ³n Final

Este taller me permitiÃ³ comprender el flujo completo de entrenamiento de un modelo de Deep Learning, desde la preparaciÃ³n de datos hasta la evaluaciÃ³n y fine-tuning. AprendÃ­ que:

1. **Fine-Tuning** mejora significativamente el rendimiento del modelo, especialmente en tareas donde los datos son limitados.
2. **ValidaciÃ³n cruzada** proporciona una evaluaciÃ³n mÃ¡s robusta del modelo, ayudando a detectar problemas como el sobreajuste.

La transferencia de aprendizaje es una tÃ©cnica poderosa que permite aprovechar modelos preentrenados para mejorar el rendimiento en tareas especÃ­ficas, incluso con datasets pequeÃ±os.
