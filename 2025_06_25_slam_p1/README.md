# Video 1: Introducción al SLAM

Este video ofrece una visión general de SLAM (Simultaneous Localization and Mapping), una tarea fundamental para robots móviles que operan en entornos desconocidos. Explica la definición de SLAM, la complejidad de resolver la localización y el mapeo simultáneamente, y la distinción entre el "front-end" (procesamiento de datos del sensor) y el "back-end" (solución del problema de estimación del estado). Se detallan los enfoques del "back-end" como los filtros de Kalman extendidos, los filtros de partículas y el SLAM basado en grafos, siendo este último el más popular. El video también cubre los tipos de grafos (de pose y de factor), las herramientas de optimización comunes como g2o, GTSAM y Ceres, y las aplicaciones prácticas de SLAM en robótica, coches autónomos y UAVs, además de su conexión con el ajuste de haces (Bundle Adjustment).

# Video 2: SLAM: Definición y Aplicaciones

Este video proporciona una descripción general de la Localización y Mapeo Simultáneos (SLAM), un problema computacional que implica construir un mapa de un entorno desconocido y, al mismo tiempo, rastrear la posición de una cámara o agente dentro de ese espacio. Aborda las diversas aplicaciones de SLAM en industrias como la realidad aumentada en teléfonos móviles, coches autónomos, drones, realidad virtual y videojuegos. El video detalla el flujo de trabajo típico de una implementación SLAM, incluyendo la entrada de sensores, la coincidencia de características, la estimación de la pose, el cierre de bucles y el ajuste de haces. Finalmente, compara SLAM con la odometría visual (VO) y la odometría visual inercial (VIO), y discute los desafíos y limitaciones de SLAM, como la dependencia de las capacidades del sensor (por ejemplo, dificultad con paredes sin rasgos distintivos) y la necesidad de una estimación precisa de los modelos de ruido de los sensores.

# Video 3: NeRF in the Wild

Este video introduce "NeRF in the Wild", una evolución del proyecto NeRF (Neural Radiance Fields) que busca reconstruir escenas 3D a partir de una colección de imágenes 2D, superando las limitaciones del NeRF original con escenas estáticas. "NeRF in the Wild" aborda las condiciones "en la naturaleza", como los cambios de iluminación, las variaciones en los ajustes de la cámara y los objetos transitorios (personas, coches). El sistema puede diferenciar entre elementos estáticos y transitorios, permitiendo la reconstrucción de escenas 3D de monumentos turísticos populares utilizando imágenes heterogéneas de internet. Técnicamente, la red neuronal se divide para aprender zonas estáticas y partes transitorias, utilizando vectores de incrustación para codificar información transitoria y de estilo. Esta tecnología ofrece control total sobre la estética de la escena, permitiendo modificar la apariencia (por ejemplo, hora del día, condiciones de iluminación, estilo fotográfico) ajustando un solo vector, lo que representa un paso significativo hacia un futuro donde la IA puede almacenar todos los detalles de una escena fotorrealista.

# Video 4: La Revolución NeRF: De Días a Segundos

Este video explora la tecnología de los Campos de Radiación Neural (NeRF) como una nueva forma de renderizado 3D que utiliza inteligencia artificial e imágenes 2D para reconstruir escenas 3D hiperrealistas. A diferencia de la fotogrametría tradicional, que infiere mallas poligonales, NeRF infiere el volumen 3D completo, capturando toda la información luminosa y manejando efectos de iluminación complejos como transparencias y reflejos. El video destaca la rápida evolución de NeRF, mencionando "NeRF in the Wild" para escenarios completos con variaciones de iluminación y "D-NeRF" para la captura 3D de personas ("nerfies"). Una de las mejoras más significativas presentada es la reducción drástica del tiempo de entrenamiento, pasando de horas o días a solo segundos. Se presentan experimentos comparando el nuevo sistema NeRF con la fotogrametría, demostrando la superioridad de NeRF en la reconstrucción de detalles, superficies reflectantes y objetos transparentes, además de su capacidad para capturar selfies en 3D de forma rápida y detallada.

# Video 5: El Futuro de los Gráficos en Tiempo Real con NeRF

Este video, con el respaldo de la Universitat Politècnica de València, aborda el futuro de los gráficos por computadora en tiempo real, centrándose en los Campos de Radiación Neural (NeRF). El presentador muestra una escena 3D hiperrealista generada por una red neuronal entrenada con múltiples imágenes, capaz de interpolar diferentes perspectivas y aprender aspectos como la iluminación, el paralaje y la oclusión. Se introduce el trazado de rayos (ray tracing) como una técnica de renderizado popular y el "Volume Ray Marching" para conjuntos de datos 3D volumétricos. El video posiciona a NeRF como una tecnología revolucionaria que, a diferencia del renderizado volumétrico tradicional, invierte el proceso utilizando imágenes existentes para supervisar el entrenamiento de una red neuronal. NeRF supera a técnicas anteriores en la comprensión de escenas 3D, especialmente en el manejo de reflejos y brillos, y resuelve el problema del uso de memoria al codificar toda la información de la escena en un archivo de solo 5 megabytes. Aunque NeRF podría no reemplazar completamente la industria de gráficos basada en polígonos, se espera que se integre en sistemas mixtos y encuentre un gran potencial en la realidad virtual, marcando un primer paso crucial en el uso de redes neuronales para gráficos hiperrealistas.

# Video 6: La Aceleración de NeRF: El Papel de NVIDIA

Este video explica cómo una nueva tecnología NeRF (Neural Radiance Fields), desarrollada por NVIDIA, está revolucionando los gráficos 3D al acelerar significativamente el proceso de renderizado. A diferencia de los modelos NeRF anteriores que tardaban horas o días en entrenarse, este nuevo enfoque puede entrenar una escena en cuestión de segundos. La clave de esta aceleración radica en asociar información específica (como color o propiedades del material) directamente con cada coordenada 3D, lo que permite que la red neuronal aprenda más rápidamente. Para abordar el posible aumento del uso de memoria, NVIDIA utiliza funciones hash para mapear coordenadas 3D a una tabla de parámetros más pequeña y de tamaño fijo. Sorprendentemente, las colisiones de hash son beneficiosas, ya que fuerzan a la red neuronal a priorizar la información más relevante para la representación de la escena, lo que lleva a la compresión de datos. Esta tecnología, acelerada por las GPU de NVIDIA, no se limita a las escenas NeRF y muestra un gran rendimiento en la codificación de imágenes de alta resolución y superficies 3D complejas, prometiendo una revolución en los gráficos 3D.

# Video 7: Gaussian Splatting: El Sucesor de NeRF

Este video presenta "Gaussian Splatting", una nueva técnica de gráficos 3D que surgió en 2023, prometiendo revolucionar la generación y visualización 3D como una alternativa más eficiente y de mayor calidad a NeRF. El concepto central de Gaussian Splatting es el uso de distribuciones gaussianas 2D como "salpicaduras de pintura" que se controlan mediante parámetros (posición, escala, color) ajustados por Deep Learning. Las ventajas clave sobre NeRF incluyen una calidad superior, especialmente en los fondos, y tiempos de renderizado significativamente más rápidos, superando los 100 fotogramas por segundo, ya que construye explícitamente la escena 3D. La eficiencia de Gaussian Splatting también permite la codificación de videos 3D (videos volumétricos), donde las "salpicaduras" pueden cambiar de posición y rotación con el tiempo, ofreciendo características como reposicionamiento de cámara y estabilización. Aunque las escenas dinámicas a menudo requieren configuraciones de cámara especializadas y las escenas se basan en renderizado volumétrico, Gaussian Splatting ha generado un gran interés en la industria y ya se está integrando en visores de realidad virtual, motores de juegos como Unity y aplicaciones móviles como Luma AI.
