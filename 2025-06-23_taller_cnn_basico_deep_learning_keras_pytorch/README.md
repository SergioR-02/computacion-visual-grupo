# ğŸ§ª Taller - Redes Convolucionales desde Cero: Reconocimiento de ImÃ¡genes con Keras

## ğŸ“… Fecha
`2025-06-23` â€“ Fecha de entrega del taller

---

## ğŸ¯ Objetivo del Taller

Construir, entrenar y evaluar un modelo de red neuronal convolucional (**CNN**) desde cero para clasificaciÃ³n de imÃ¡genes usando el dataset CIFAR-10. El objetivo es comprender los componentes fundamentales de una CNN, implementar una arquitectura completa de deep learning, y evaluar su rendimiento en una tarea real de visiÃ³n por computador con 10 clases diferentes de objetos.

---

## ğŸ§  Conceptos Aprendidos

Lista los principales conceptos aplicados:

- [x] Arquitectura de Redes Neuronales Convolucionales (CNN)
- [x] Capas convolucionales y detecciÃ³n de caracterÃ­sticas
- [x] Pooling y reducciÃ³n de dimensionalidad
- [x] Funciones de activaciÃ³n ReLU y Softmax
- [x] RegularizaciÃ³n con Dropout para prevenir overfitting
- [x] OptimizaciÃ³n con Adam y funciones de pÃ©rdida
- [x] EvaluaciÃ³n de modelos con mÃ©tricas de clasificaciÃ³n
- [x] VisualizaciÃ³n de curvas de entrenamiento y matrices de confusiÃ³n

---

## ğŸ”§ Herramientas y Entornos

Especifica los entornos usados:

- Python (`tensorflow>=2.16.0`, `keras`, `numpy`, `matplotlib`)
- Jupyter Notebooks para desarrollo interactivo
- Scikit-learn para mÃ©tricas de evaluaciÃ³n
- Seaborn para visualizaciones avanzadas
- Dataset CIFAR-10 con 10 clases de objetos



---

## ğŸ“ Estructura del Proyecto

```
2025-06-23_taller_cnn_basico_deep_learning_keras_pytorch/
â”œâ”€â”€ Keras/                      # ImplementaciÃ³n completa en TensorFlow/Keras
â”‚   â”œâ”€â”€ src/                   # CÃ³digo fuente modular
â”‚   â”‚   â”œâ”€â”€ data_loader.py     # Cargador y preprocesador de datos
â”‚   â”‚   â”œâ”€â”€ model.py           # DefiniciÃ³n de arquitecturas CNN
â”‚   â”‚   â”œâ”€â”€ train_model.py     # Script de entrenamiento
â”‚   â”‚   â””â”€â”€ utils.py           # Utilidades y funciones auxiliares
â”‚   â”œâ”€â”€ notebooks/             # Jupyter Notebooks interactivos
â”‚   â”‚   â”œâ”€â”€ 01_data_exploration.ipynb   # ExploraciÃ³n de datos CIFAR-10
â”‚   â”‚   â””â”€â”€ 02_cnn_model.ipynb          # ConstrucciÃ³n y entrenamiento CNN
â”‚   â”œâ”€â”€ models/                # Modelos entrenados guardados
â”‚   â”‚   â”œâ”€â”€ cnn_cifar10_model.h5        # Modelo en formato H5
â”‚   â”‚   â”œâ”€â”€ cnn_cifar10_model.keras     # Modelo en formato Keras
â”‚   â”‚   â””â”€â”€ cnn_cifar10_model.weights.h5 # Pesos del modelo
â”‚   â”œâ”€â”€ requirements.txt       # Dependencias del proyecto
â”‚   â””â”€â”€ INSTALL.md            # GuÃ­a de instalaciÃ³n
â”œâ”€â”€ Evidencias/               # Capturas y grÃ¡ficos de resultados
â”‚   â”œâ”€â”€ Evidencia.png         # VisualizaciÃ³n del dataset
â”‚   â””â”€â”€ Precision_Perdida_Modelo_Evidencia.png # Curvas de entrenamiento
â””â”€â”€ README.md
```

---

## ğŸ§ª ImplementaciÃ³n

Explica el proceso:

### ğŸ”¹ Etapas realizadas
1. **Carga y exploraciÃ³n de datos**: AnÃ¡lisis del dataset CIFAR-10 con 50,000 imÃ¡genes de entrenamiento.
2. **Preprocesamiento**: NormalizaciÃ³n de pÃ­xeles, one-hot encoding y separaciÃ³n de conjuntos de validaciÃ³n.
3. **DiseÃ±o de arquitectura CNN**: ConstrucciÃ³n de modelo convolucional con 3 capas Conv2D y regularizaciÃ³n.
4. **Entrenamiento del modelo**: OptimizaciÃ³n con Adam, monitoreo de mÃ©tricas y early stopping.
5. **EvaluaciÃ³n y anÃ¡lisis**: MÃ©tricas de accuracy, matriz de confusiÃ³n y anÃ¡lisis de predicciones.
6. **ExperimentaciÃ³n**: Pruebas con diferentes hiperparÃ¡metros y arquitecturas mejoradas.

### ğŸ”¹ CÃ³digo relevante

Arquitectura CNN bÃ¡sica implementada:

```python
def create_cnn_model(input_shape=(32, 32, 3), num_classes=10):
    """
    Crea un modelo CNN para clasificaciÃ³n de imÃ¡genes CIFAR-10
    
    Returns:
        modelo CNN compilado con arquitectura optimizada
    """
    model = models.Sequential([
        # Primera capa convolucional - Detecta caracterÃ­sticas bÃ¡sicas
        layers.Conv2D(32, (3, 3), activation='relu', 
                     input_shape=input_shape, name='conv2d_1'),
        layers.MaxPooling2D((2, 2), name='maxpool_1'),
        
        # Segunda capa convolucional - CaracterÃ­sticas mÃ¡s complejas
        layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_2'),
        layers.MaxPooling2D((2, 2), name='maxpool_2'),
        
        # Tercera capa convolucional - CaracterÃ­sticas de alto nivel
        layers.Conv2D(64, (3, 3), activation='relu', name='conv2d_3'),
        
        # Flatten para conectar con capas densas
        layers.Flatten(name='flatten'),
        
        # Capas densas para clasificaciÃ³n final
        layers.Dense(64, activation='relu', name='dense_1'),
        layers.Dropout(0.5, name='dropout'),  # RegularizaciÃ³n
        layers.Dense(num_classes, activation='softmax', name='output')
    ])
    
    return model
```

Cargador de datos CIFAR-10 con preprocesamiento:

```python
class DataLoader:
    """Clase para cargar y preprocesar datos CIFAR-10"""
    
    def __init__(self):
        self.class_names = [
            'aviÃ³n', 'automÃ³vil', 'pÃ¡jaro', 'gato', 'ciervo', 
            'perro', 'rana', 'caballo', 'barco', 'camiÃ³n'
        ]
        
    def load_and_preprocess(self, validation_split=0.1):
        """
        Carga y preprocesa el dataset CIFAR-10
        
        Returns:
            tuple: Datos procesados (train, val, test)
        """
        # Cargar datos originales
        (x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()
        
        # Normalizar pÃ­xeles al rango [0, 1]
        x_train = x_train.astype('float32') / 255.0
        x_test = x_test.astype('float32') / 255.0
        
        # Convertir etiquetas a one-hot encoding
        y_train_onehot = keras.utils.to_categorical(y_train, 10)
        y_test_onehot = keras.utils.to_categorical(y_test, 10)
        
        # Separar conjunto de validaciÃ³n
        val_size = int(len(x_train) * validation_split)
        indices = np.random.permutation(len(x_train))
        
        val_indices = indices[:val_size]
        train_indices = indices[val_size:]
        
        x_val = x_train[val_indices]
        y_val = y_train_onehot[val_indices]
        x_train = x_train[train_indices]
        y_train = y_train_onehot[train_indices]
        
        return (x_train, y_train, x_val, y_val, x_test, y_test_onehot)
```

Entrenamiento con monitoreo de mÃ©tricas:

```python
def train_model(model, x_train, y_train, x_val, y_val, epochs=20):
    """
    Entrena el modelo CNN con configuraciÃ³n optimizada
    """
    # Compilar modelo
    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    
    # Callbacks para optimizaciÃ³n
    callbacks = [
        keras.callbacks.EarlyStopping(
            monitor='val_accuracy',
            patience=5,
            restore_best_weights=True
        ),
        keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-7
        )
    ]
    
    # Entrenar modelo
    history = model.fit(
        x_train, y_train,
        batch_size=32,
        epochs=epochs,
        validation_data=(x_val, y_val),
        callbacks=callbacks,
        verbose=1
    )
    
    return history
```

---

## ğŸ“Š Resultados Visuales

### ğŸ“Œ Este taller **requiere explÃ­citamente evidencias visuales**:

Las evidencias muestran el desarrollo completo del sistema de CNN:
- **Dataset CIFAR-10**: VisualizaciÃ³n de las 10 clases con ejemplos representativos
- **Arquitectura del modelo**: Resumen de capas y parÃ¡metros totales (â‰ˆ1.2M parÃ¡metros)
- **Curvas de entrenamiento**: EvoluciÃ³n de accuracy y loss durante 20 Ã©pocas
- **Matriz de confusiÃ³n**: AnÃ¡lisis detallado de predicciones por clase
- **Ejemplos de clasificaciÃ³n**: Predicciones correctas e incorrectas del modelo

![Evidencia](./Evidencias/Evidencia.png)

![Precision_Perdida_Modelo_Evidencia](./Evidencias/Precision_Perdida_Modelo_Evidencia.png)

### ğŸ”¹ Resultados alcanzados:

- **Accuracy en entrenamiento**: ~85% despuÃ©s de 20 Ã©pocas
- **Accuracy en validaciÃ³n**: ~75% con generalizaciÃ³n aceptable
- **Accuracy en test**: ~74% confirmando la capacidad del modelo
- **Clases mejor clasificadas**: AviÃ³n, barco, camiÃ³n (objetos con formas distintivas)
- **Clases mÃ¡s difÃ­ciles**: Gato vs perro, ciervo vs caballo (similitud visual)
- **ParÃ¡metros totales**: 1,250,858 parÃ¡metros entrenables
- **Tiempo de entrenamiento**: ~15 minutos en CPU estÃ¡ndar

---

## ğŸ§© Prompts Usados

Enumera los prompts utilizados:

```text

"Desarrollar pipeline de entrenamiento con callbacks de early stopping, reducciÃ³n de learning rate, y monitoreo de mÃ©tricas de accuracy y loss"

"Crear visualizaciones de curvas de entrenamiento, matriz de confusiÃ³n, y ejemplos de predicciones correctas e incorrectas del modelo CNN"

"Implementar evaluaciÃ³n completa del modelo con mÃ©tricas de clasificaciÃ³n, anÃ¡lisis por clase, y guardado/carga de modelos entrenados"
```

---

## ğŸ’¬ ReflexiÃ³n Final

Este taller me permitiÃ³ comprender profundamente el funcionamiento de las **Redes Neuronales Convolucionales** y su aplicaciÃ³n prÃ¡ctica en problemas de visiÃ³n por computador. La experiencia de construir una CNN desde cero fue especialmente valiosa para entender cÃ³mo cada componente contribuye al proceso de reconocimiento de imÃ¡genes.

La parte mÃ¡s compleja fue encontrar el equilibrio correcto entre **capacidad del modelo y overfitting**. Experimentar con diferentes valores de dropout, learning rates, y arquitecturas me ayudÃ³ a comprender cÃ³mo cada hiperparÃ¡metro afecta el rendimiento. El uso de callbacks como early stopping y reducciÃ³n de learning rate fue crucial para obtener un modelo robusto.

Para futuros proyectos, aplicarÃ­a estos conocimientos en **arquitecturas mÃ¡s avanzadas** como ResNet, transfer learning con modelos preentrenados, y tÃ©cnicas de data augmentation. TambiÃ©n serÃ­a interesante explorar aplicaciones especÃ­ficas como diagnÃ³stico mÃ©dico por imÃ¡genes, detecciÃ³n de objetos en tiempo real, y procesamiento de imÃ¡genes satelitales.

