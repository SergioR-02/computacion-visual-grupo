# üß™ Taller - YOLO: Detecci√≥n de Objetos en Webcam en Tiempo Real

## üìÖ Fecha
`2025-06-23` ‚Äì Fecha de entrega del taller

---

## üéØ Objetivo del Taller

Implementar un sistema de **detecci√≥n de objetos en tiempo real** usando el modelo YOLO (You Only Look Once) v8 con entrada de webcam. El objetivo es comprender c√≥mo funcionan los modelos de detecci√≥n de objetos modernos, implementar una aplicaci√≥n pr√°ctica que procese video en vivo, y analizar el rendimiento de la detecci√≥n con m√©tricas de precisi√≥n y velocidad (FPS) en tiempo real.

---

## üß† Conceptos Aprendidos

Lista los principales conceptos aplicados:

- [x] Arquitectura YOLO (You Only Look Once) para detecci√≥n de objetos
- [x] Modelos pre-entrenados y transfer learning
- [x] Procesamiento de video en tiempo real con OpenCV
- [x] Bounding boxes, confianza y detecci√≥n de m√∫ltiples clases
- [x] Optimizaci√≥n de rendimiento y c√°lculo de FPS
- [x] Visualizaci√≥n de resultados con anotaciones din√°micas
- [x] Integraci√≥n de c√°mara web con procesamiento de im√°genes
- [x] An√°lisis de rendimiento en aplicaciones de visi√≥n por computador

---

## üîß Herramientas y Entornos

Especifica los entornos usados:

- Python (`ultralytics>=8.0.0`, `opencv-python`, `torch`, `torchvision`)
- YOLOv8 modelo pre-entrenado (yolov8n.pt)
- OpenCV para captura y procesamiento de video
- NumPy para manipulaci√≥n de arrays
- Matplotlib para visualizaciones adicionales



---

## üìÅ Estructura del Proyecto

```
2025-06-23_taller_yolo_deteccion_webcam_tiempo_real/
‚îú‚îÄ‚îÄ python/                         # Implementaci√≥n en Python
‚îÇ   ‚îú‚îÄ‚îÄ yolo_webcam_detection.py   # Detector principal con clase completa
‚îÇ   ‚îú‚îÄ‚îÄ simple_yolo_detection.py   # Versi√≥n simplificada para demos
‚îÇ   ‚îú‚îÄ‚îÄ performance_testing.py     # Scripts de an√°lisis de rendimiento
‚îÇ   ‚îú‚îÄ‚îÄ yolov8n.pt                # Modelo YOLO pre-entrenado
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt           # Dependencias del proyecto
‚îÇ   ‚îî‚îÄ‚îÄ install_dependencies.bat   # Script de instalaci√≥n Windows
‚îú‚îÄ‚îÄ Evidencia/                     # Capturas y resultados
‚îÇ   ‚îú‚îÄ‚îÄ Evidencia.png             # Captura de detecci√≥n en funcionamiento
‚îÇ   ‚îî‚îÄ‚îÄ Evidencia2.png            # M√∫ltiples objetos detectados
‚îî‚îÄ‚îÄ README.md
```


---

## üß™ Implementaci√≥n

Explica el proceso:

### üîπ Etapas realizadas
1. **Configuraci√≥n del entorno**: Instalaci√≥n de Ultralytics, OpenCV y dependencias para YOLO.
2. **Integraci√≥n del modelo**: Carga del modelo YOLOv8 pre-entrenado con 80 clases COCO.
3. **Captura de video**: Configuraci√≥n de webcam con OpenCV y manejo de frames.
4. **Procesamiento en tiempo real**: Aplicaci√≥n de YOLO frame por frame con optimizaciones.
5. **Visualizaci√≥n de resultados**: Dibujado de bounding boxes, etiquetas y confianza.
6. **Optimizaci√≥n de rendimiento**: Medici√≥n de FPS y ajuste de par√°metros para tiempo real.

### üîπ C√≥digo relevante

Detector YOLO principal con clase completa:

```python
class YOLOWebcamDetector:
    """
    Real-time object detection using YOLO and webcam
    """
    
    def __init__(self, model_name='yolov8n.pt', confidence_threshold=0.5):
        """
        Initialize the YOLO detector with optimized parameters
        """
        self.model = YOLO(model_name)
        self.confidence_threshold = confidence_threshold
        self.fps_history = []
        self.frame_count = 0
        
        # Colors for different classes (BGR format)
        self.colors = [
            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
            (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)
        ]
        
    def draw_detections(self, frame, detections):
        """
        Draw bounding boxes, labels and confidence on frame
        """
        for detection in detections:
            boxes = detection.boxes
            if boxes is not None:
                for box in boxes:
                    # Extract coordinates and confidence
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    confidence = float(box.conf[0])
                    class_id = int(box.cls[0])
                    
                    if confidence >= self.confidence_threshold:
                        # Get class name and color
                        class_name = self.model.names[class_id]
                        color = self.colors[class_id % len(self.colors)]
                        
                        # Draw bounding box
                        cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                        
                        # Draw label with confidence
                        label = f"{class_name}: {confidence:.2f}"
                        cv2.putText(frame, label, (x1, y1-10), 
                                  cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        return frame
```

Procesamiento en tiempo real optimizado:

```python
def run_detection(self):
    """
    Main detection loop with performance optimization
    """
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    cap.set(cv2.CAP_PROP_FPS, 30)
    
    if not cap.isOpened():
        print("Error: Cannot access webcam")
        return
    
    print("üé• Starting YOLO detection... Press 'q' to quit")
    
    while True:
        start_time = time.time()
        
        # Capture frame
        ret, frame = cap.read()
        if not ret:
            break
            
        # Flip for mirror effect
        frame = cv2.flip(frame, 1)
        
        # YOLO inference
        results = self.model(frame, conf=self.confidence_threshold, verbose=False)
        
        # Draw detections
        frame = self.draw_detections(frame, results)
        
        # Calculate and display FPS
        end_time = time.time()
        fps = 1.0 / (end_time - start_time)
        self.fps_history.append(fps)
        
        # Keep only last 30 FPS values for average
        if len(self.fps_history) > 30:
            self.fps_history.pop(0)
            
        avg_fps = sum(self.fps_history) / len(self.fps_history)
        
        # Display FPS on frame
        cv2.putText(frame, f"FPS: {avg_fps:.1f}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # Show frame
        cv2.imshow("YOLO Real-time Detection", frame)
        
        # Exit on 'q' key
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
```

Versi√≥n simplificada para demostraci√≥n:

```python
def simple_yolo_detection():
    """
    Simple YOLO detection with minimal code for quick demos
    """
    # Load YOLO model
    model = YOLO('yolov8n.pt')
    
    # Initialize webcam
    cap = cv2.VideoCapture(0)
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # Flip frame for mirror effect
        frame = cv2.flip(frame, 1)
        
        # Run YOLO inference
        results = model(frame)
        
        # Draw results on frame (automatic annotation)
        annotated_frame = results[0].plot()
        
        # Calculate and display FPS
        current_time = time.time()
        fps = 1.0 / (current_time - prev_time)
        cv2.putText(annotated_frame, f"FPS: {fps:.1f}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # Display frame
        cv2.imshow("Simple YOLO Detection", annotated_frame)
        
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
```

---

## üìä Resultados Visuales

### üìå Este taller **requiere expl√≠citamente evidencias visuales**:


Las evidencias muestran el funcionamiento completo del sistema de detecci√≥n YOLO:
- **Detecci√≥n m√∫ltiple**: Sistema capaz de detectar varios objetos simult√°neamente
- **Bounding boxes precisos**: Delimitaci√≥n exacta de objetos con coordenadas optimizadas
- **Etiquetas informativas**: Nombres de clases con porcentajes de confianza
- **Rendimiento en tiempo real**: FPS promedio de 25-30 en hardware est√°ndar
- **Interfaz visual clara**: Colores distintivos y texto legible para cada clase

![Evidencia](./Evidencia/Evidencia.png)

![Evidencia2](./Evidencia/Evidencia2.png)

### üîπ Caracter√≠sticas implementadas:

- **Modelo YOLOv8n**: Versi√≥n nano optimizada para velocidad en tiempo real
- **80 clases COCO**: Detecci√≥n de objetos cotidianos (persona, auto, animal, etc.)
- **Umbral de confianza configurable**: Filtrado de detecciones con baja probabilidad
- **FPS en tiempo real**: Optimizaci√≥n para mantener >20 FPS en webcam
- **Interfaz interactiva**: Control mediante teclado y visualizaci√≥n en vivo
- **M√∫ltiples versiones**: Implementaci√≥n completa y simplificada para diferentes usos

---

## üß© Prompts Usados

Enumera los prompts utilizados:

```text
"Implementar sistema de detecci√≥n de objetos en tiempo real usando YOLOv8 con webcam, incluyendo captura de video, procesamiento frame por frame, y visualizaci√≥n de bounding boxes con etiquetas"

"Crear clase completa YOLOWebcamDetector que maneje modelo YOLO, dibuje detecciones con colores por clase, calcule FPS en tiempo real, y optimice rendimiento para aplicaciones en vivo"

"Desarrollar versi√≥n simplificada de detecci√≥n YOLO para demostraciones r√°pidas, con c√≥digo m√≠nimo pero funcional para mostrar capacidades b√°sicas del modelo"

"Optimizar rendimiento de detecci√≥n en tiempo real ajustando resoluci√≥n de webcam, umbral de confianza, y par√°metros de OpenCV para mantener FPS estables"

"Implementar sistema de an√°lisis de rendimiento que mida FPS promedio, tiempo de inferencia, y m√©tricas de detecci√≥n para evaluar eficiencia del sistema"
```



---

## üí¨ Reflexi√≥n Final

Este taller me permiti√≥ experimentar con **modelos de detecci√≥n de objetos de √∫ltima generaci√≥n** y comprender las diferencias fundamentales entre clasificaci√≥n y detecci√≥n. YOLO representa un enfoque revolucionario que realiza detecci√≥n y clasificaci√≥n en una sola pasada, logrando velocidades impresionantes para aplicaciones en tiempo real.

La parte m√°s desafiante fue **optimizar el rendimiento** para mantener FPS estables sin sacrificar precisi√≥n. Experimentar con diferentes resoluciones, umbrales de confianza, y configuraciones de OpenCV me ayud√≥ a entender el equilibrio entre velocidad y calidad en aplicaciones de visi√≥n por computador en vivo.

Para futuros proyectos, aplicar√≠a estos conocimientos en **sistemas de videovigilancia inteligente**, detecci√≥n de objetos en rob√≥tica m√≥vil, an√°lisis de tr√°fico vehicular, y aplicaciones de realidad aumentada. Tambi√©n ser√≠a interesante explorar entrenamiento custom de YOLO para objetos espec√≠ficos y optimizaci√≥n con TensorRT para hardware especializado.

---
