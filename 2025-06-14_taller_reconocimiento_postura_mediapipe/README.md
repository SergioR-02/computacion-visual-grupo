# ğŸ§ª Taller - Reconocimiento de Acciones Simples con DetecciÃ³n de Postura

## ğŸ” Objetivo del taller

Implementar el reconocimiento de acciones simples (como sentarse, levantar brazos o caminar frente a cÃ¡mara) usando MediaPipe Pose para detectar la postura corporal. El objetivo es utilizar puntos clave del cuerpo (landmarks) para interpretar la acciÃ³n y responder visual o sonoramente.

## ğŸ› ï¸ InstalaciÃ³n

### Paso 1: Instalar dependencias

```bash
cd python
pip install -r requirements.txt
```

O ejecutar el archivo batch:

```bash
./install.bat
```

### Dependencias necesarias:

- `mediapipe>=0.10.0` - Para detecciÃ³n de postura corporal
- `opencv-python>=4.8.0` - Para captura de video y visualizaciÃ³n
- `numpy>=1.24.0` - Para cÃ¡lculos matemÃ¡ticos
- `pygame>=2.5.0` - Para efectos de sonido

## ğŸš€ EjecuciÃ³n

### OpciÃ³n 1: Ejemplo Simple (Recomendado para comenzar)

```bash
python simple_example.py
```

Este ejemplo incluye detecciÃ³n bÃ¡sica de:

- ğŸ™Œ Brazos arriba
- ğŸª‘ Persona sentada
- ğŸ§ De pie

### OpciÃ³n 2: Demo Interactivo

```bash
python interactive_demo.py
```

Demo guiado paso a paso que te enseÃ±a cada acciÃ³n:

- Instrucciones claras en pantalla
- RetroalimentaciÃ³n visual
- Progreso de detecciÃ³n en tiempo real

### OpciÃ³n 3: Sistema Completo

```bash
python main.py
```

Sistema completo con detecciÃ³n avanzada de:

- ğŸ™Œ Brazos arriba
- ğŸª‘ Sentado
- ğŸš¶ Caminando
- ğŸ¤¸ Agachado
- ï¿½ Brazos extendidos
- ï¿½ğŸ§ De pie

## ğŸ¯ Acciones Detectables

### 1. ğŸ™Œ Brazos Arriba

- **DescripciÃ³n**: Levantar ambos brazos por encima de la cabeza
- **CondiciÃ³n**: Ambas muÃ±ecas por encima de la nariz
- **LÃ³gica**: `left_wrist_y < nose_y AND right_wrist_y < nose_y`

### 2. ğŸª‘ Sentado

- **DescripciÃ³n**: Persona sentada en una silla
- **CondiciÃ³n**: Caderas cerca del nivel de las rodillas
- **LÃ³gica**: `abs(hip_y - knee_y) < threshold`

### 3. ğŸš¶ Caminando

- **DescripciÃ³n**: Movimiento de caminar frente a la cÃ¡mara
- **CondiciÃ³n**: VariaciÃ³n en posiciÃ³n de los pies
- **LÃ³gica**: AnÃ¡lisis de historial de movimiento de pies

### 4. ğŸ¤¸ Agachado

- **DescripciÃ³n**: PosiciÃ³n en cuclillas
- **CondiciÃ³n**: Torso comprimido, rodillas dobladas
- **LÃ³gica**: `torso_height < threshold AND knees_bent`

### 5. ğŸ¤² Brazos Extendidos

- **DescripciÃ³n**: Brazos extendidos horizontalmente
- **CondiciÃ³n**: MuÃ±ecas al nivel de hombros, separadas horizontalmente
- **LÃ³gica**: `vertical_diff < threshold AND horizontal_diff > threshold`

### 6. ğŸ§ De pie

- **DescripciÃ³n**: Postura neutral sin acciones especÃ­ficas
- **CondiciÃ³n**: Estado por defecto cuando no se detectan otras acciones

## ğŸ§  Ejemplos de Reglas Condicionales

```python
# DetecciÃ³n de brazos arriba
if left_wrist_y < nose_y and right_wrist_y < nose_y:
    print("Â¡Ambos brazos arriba!")

# DetecciÃ³n de persona sentada
elif abs(left_hip_y - left_knee_y) < threshold:
    print("Persona sentada")

# DetecciÃ³n de brazos extendidos
elif (abs(left_wrist_y - left_shoulder_y) < vertical_threshold and
      abs(left_wrist_x - left_shoulder_x) > horizontal_threshold):
    print("Brazos extendidos")

# DetecciÃ³n de agachado
elif torso_height < normal_torso_threshold:
    print("Persona agachada")
```

## ğŸ“Š CaracterÃ­sticas del Sistema

### ğŸ¥ DetecciÃ³n en Tiempo Real

- âœ… Captura de webcam a 30 FPS
- âœ… Procesamiento de 33 landmarks corporales
- âœ… VisualizaciÃ³n de conexiones del esqueleto
- âœ… Indicadores visuales por acciÃ³n

### ğŸ¯ Sistema de Confianza

- âœ… CÃ¡lculo de confianza por acciÃ³n (0.0 - 1.0)
- âœ… Filtrado por visibilidad de landmarks
- âœ… DetecciÃ³n robusta con umbrales ajustables
- âœ… Historial para acciones de movimiento

### ğŸ¨ Interfaz Visual

- âœ… Colores diferentes por tipo de landmark
- âœ… InformaciÃ³n en tiempo real en pantalla
- âœ… Efecto espejo para facilidad de uso
- âœ… Barra de progreso para confirmaciÃ³n

### ğŸ”Š Efectos de Sonido

- âœ… Tonos Ãºnicos por cada acciÃ³n
- âœ… ActivaciÃ³n/desactivaciÃ³n con tecla 's'
- âœ… GeneraciÃ³n procedural de audio

## ğŸ® Controles

### Sistema Principal (main.py)

- **'q'**: Salir del programa
- **'s'**: Activar/desactivar sonidos
- **'r'**: Reiniciar historial de movimiento

### Demo Interactivo (interactive_demo.py)

- **'q'**: Salir del programa
- **'r'**: Reiniciar demo completo
- **'n'**: Saltar a siguiente acciÃ³n

## ğŸ”§ PersonalizaciÃ³n

### Ajustar Sensibilidad

En `main.py`, puedes modificar los umbrales:

```python
# Umbrales para detecciÃ³n de sentado
sitting_threshold = height * 0.15  # Ajustar para mayor/menor sensibilidad

# Umbral para detecciÃ³n de caminata
movement_threshold = width * 0.02  # Reducir para mayor sensibilidad

# Confianza mÃ­nima para MediaPipe
min_detection_confidence=0.5  # Aumentar para mayor precisiÃ³n
min_tracking_confidence=0.5   # Aumentar para tracking mÃ¡s estable
```

### Agregar Nuevas Acciones

1. Crear funciÃ³n de detecciÃ³n en la clase `PoseActionDetector`
2. Agregar llamada en `detect_action()`
3. Agregar color y sonido en los mapeos correspondientes

### Ejemplo de Nueva AcciÃ³n:

```python
def detect_jumping(self, landmarks, width: int, height: int) -> bool:
    """Detectar si la persona estÃ¡ saltando"""
    if not landmarks:
        return False

    # Obtener posiciones de pies
    left_foot_x, left_foot_y = self.get_landmark_position(
        landmarks, self.mp_pose.PoseLandmark.LEFT_FOOT_INDEX, width, height)
    right_foot_x, right_foot_y = self.get_landmark_position(
        landmarks, self.mp_pose.PoseLandmark.RIGHT_FOOT_INDEX, width, height)

    # LÃ³gica: pies por encima del nivel normal (simplificado)
    normal_ground_level = height * 0.9  # 90% de la altura

    return left_foot_y < normal_ground_level and right_foot_y < normal_ground_level
```

## ğŸ”Š Sistema de Sonido

El sistema incluye generaciÃ³n procedural de tonos Ãºnicos para cada acciÃ³n:

- **ğŸ™Œ Brazos Arriba**: 800 Hz (tono agudo)
- **ğŸª‘ Sentado**: 400 Hz (tono medio)
- **ğŸ¤¸ Agachado**: 300 Hz (tono grave)
- **ğŸ¤² Brazos Extendidos**: 600 Hz (tono medio-agudo)
- **ğŸš¶ Caminando**: 500 Hz (tono medio)

## ğŸ› SoluciÃ³n de Problemas

### âŒ Error de CÃ¡mara

```
Error: No se pudo abrir la cÃ¡mara
```

**Soluciones**:

- Verificar que no haya otras aplicaciones usando la webcam
- Cambiar el Ã­ndice de cÃ¡mara: `cv2.VideoCapture(1)` en lugar de `(0)`
- Reiniciar la aplicaciÃ³n

### âŒ MediaPipe no detecta postura

**Causas posibles**:

- IluminaciÃ³n insuficiente
- Persona muy lejos de la cÃ¡mara
- Postura parcialmente fuera del encuadre

**Soluciones**:

- Mejorar iluminaciÃ³n del ambiente
- Acercarse a la cÃ¡mara (distancia recomendada: 1-2 metros)
- Reducir `min_detection_confidence` a 0.3
- Asegurar que todo el cuerpo estÃ© visible

### âŒ DetecciÃ³n incorrecta o inestable

**Soluciones**:

- Ajustar umbrales en las funciones de detecciÃ³n
- Mejorar condiciones de iluminaciÃ³n
- Usar fondo uniforme y contrastante
- Calibrar para tu altura/proporciones especÃ­ficas
- Aumentar `min_tracking_confidence` para mayor estabilidad

### âŒ Error de instalaciÃ³n de dependencias

```
ERROR: Could not build wheels for mediapipe
```

**Soluciones**:

- Actualizar pip: `python -m pip install --upgrade pip`
- Instalar Visual Studio Build Tools (Windows)
- Usar Python 3.8-3.11 (versiones compatibles)

## ğŸ“ˆ MÃ©tricas y Rendimiento

- **FPS tÃ­pico**: 15-30 (dependiendo del hardware)
- **Latencia**: < 100ms para detecciÃ³n
- **PrecisiÃ³n**: ~85-95% en condiciones Ã³ptimas
- **Landmarks procesados**: 33 puntos corporales
- **Memoria RAM**: ~200-500MB durante ejecuciÃ³n

## ğŸ“ Conceptos TÃ©cnicos

### Landmarks de MediaPipe Pose

El sistema utiliza 33 puntos clave del cuerpo:

- **0**: Nariz
- **11, 12**: Hombros (izquierdo, derecho)
- **13, 14**: Codos (izquierdo, derecho)
- **15, 16**: MuÃ±ecas (izquierda, derecha)
- **23, 24**: Caderas (izquierda, derecha)
- **25, 26**: Rodillas (izquierda, derecha)
- **31, 32**: Pies (izquierdo, derecho)

### Algoritmos de DetecciÃ³n

1. **DetecciÃ³n basada en posiciÃ³n relativa**: Comparar coordenadas Y de landmarks
2. **DetecciÃ³n basada en distancia**: Calcular distancias euclidianas
3. **DetecciÃ³n temporal**: AnÃ¡lisis de historial de movimientos
4. **DetecciÃ³n de Ã¡ngulos**: Calcular Ã¡ngulos entre segmentos corporales

## ğŸ”¬ Extensiones Sugeridas

### Nivel BÃ¡sico

1. **Contador de repeticiones** - Contar flexiones, sentadillas
2. **Detector de posturas de yoga** - Asanas bÃ¡sicas
3. **Sistema de puntuaciÃ³n** - GamificaciÃ³n de ejercicios

### Nivel Intermedio

4. **AnÃ¡lisis de simetrÃ­a corporal** - CorrecciÃ³n postural
5. **DetecciÃ³n de ejercicios especÃ­ficos** - Rutinas de gimnasio
6. **IntegraciÃ³n con base de datos** - Guardar progreso

### Nivel Avanzado

7. **Reconocimiento de gestos de manos** (MediaPipe Hands)
8. **DetecciÃ³n de expresiones faciales** (MediaPipe Face)
9. **Control de dispositivos IoT** - DomÃ³tica por gestos
10. **AnÃ¡lisis biomecÃ¡nico** - MÃ©tricas deportivas avanzadas

## ğŸ† DesafÃ­os Propuestos

### ğŸ¥‰ Bronce

- Implementar detecciÃ³n de "manos en la cintura"
- Agregar contador de tiempo por acciÃ³n
- Crear sistema de puntuaciÃ³n simple

### ğŸ¥ˆ Plata

- Detectar secuencias de movimientos (ej: saludo completo)
- Implementar filtros de suavizado para detecciÃ³n mÃ¡s estable
- Agregar calibraciÃ³n automÃ¡tica por usuario

### ğŸ¥‡ Oro

- Crear sistema de entrenamiento personal interactivo
- Implementar anÃ¡lisis de calidad de movimiento
- Desarrollar API REST para integraciÃ³n con otras aplicaciones

## ğŸ“š Referencias y Recursos

### DocumentaciÃ³n Oficial

- [MediaPipe Pose](https://google.github.io/mediapipe/solutions/pose.html)
- [OpenCV Python](https://opencv-python-tutroals.readthedocs.io/)
- [Pygame Documentation](https://www.pygame.org/docs/)

### Tutoriales Adicionales

- [MediaPipe Python Examples](https://github.com/google/mediapipe/tree/master/mediapipe/python)
- [Computer Vision with Python](https://opencv-python-tutroals.readthedocs.io/en/latest/)

### Datasets y Modelos

- [COCO Pose Dataset](https://cocodataset.org/#keypoints-2020)
- [Human3.6M Dataset](http://vision.imar.ro/human3.6m/)

---

**Â¡Felicitaciones!** ğŸ‰ Has completado el taller de reconocimiento de acciones simples con detecciÃ³n de postura. Este proyecto te introduce a los conceptos fundamentales de visiÃ³n por computadora y anÃ¡lisis de movimiento humano.
